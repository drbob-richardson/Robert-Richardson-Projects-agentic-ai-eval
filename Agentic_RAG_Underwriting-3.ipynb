{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic AI Underwriting Demo (BOP)\n",
        "\n",
        "*A hands-on look at how “agentic” AI can support straight-through underwriting for Businessowners Policies (BOP)—with transparent reasoning, safe hand-offs, and repeatable evaluation.*\n",
        "\n",
        "## What this shows\n",
        "- **Practical workflow:** An AI assistant that breaks underwriting into smaller decisions (check appetite, gather missing context, confirm evidence, and finalize or refer).\n",
        "- **Clear reasons:** Each decision includes short, human-readable rationale and the specific rule or document section it relied on.\n",
        "- **Safe-fail behavior:** When the case is ambiguous or information is insufficient, the system recommends **send-to-human** review instead of forcing a decision.\n",
        "- **Repeatable testing:** The demo runs on a **realistic synthetic dataset**, so new AI methods can be evaluated fairly as the technology evolves.\n",
        "\n",
        "## Why it matters for actuaries\n",
        "- **Consistency & speed:** Routine cases can move faster while edge cases are routed for expert review.\n",
        "- **Auditability:** Decisions are tied to evidence, which helps with governance and peer review.\n",
        "- **Future-proofing:** Because the dataset is reusable, we can compare today’s models with tomorrow’s “next big thing” on the same scenarios.\n",
        "\n",
        "## What you’ll see in the notebook\n",
        "1. **Setup:** Load the demo dataset (guidebook excerpts + sample BOP applications).\n",
        "2. **Agent flow:** The assistant checks appetite, resolves uncertainties, and either finalizes or refers.\n",
        "3. **Reason capture:** The assistant records short reasons and the rule(s) consulted.\n",
        "4. **Evaluation:** We score outcomes (accept/reject/refer) and rationale quality against ground truth.\n",
        "5. **Summary:** Simple tables/plots that show accuracy, referral behavior, and reason alignment.\n",
        "\n",
        "> **No code required to browse:** You can scroll to the outputs to see example cases, decisions, and summaries. Running cells is optional.\n",
        "\n",
        "## What makes this different\n",
        "- **Agentic design:** Instead of one big answer, the assistant takes **small, verifiable steps** and can reconsider when signals conflict.\n",
        "- **Evidence-first:** Rationales point back to the exact guideline passages used.\n",
        "- **Human-in-the-loop by design:** The system prefers referral when rules or data don’t clearly support a decision.\n",
        "- **Evaluation you can trust:** Results are produced on a curated, **non-proprietary** dataset that can be shared and rerun.\n",
        "\n",
        "## About the dataset\n",
        "This demo uses a **synthetic underwriting guidebook** and **scripted application scenarios** that mimic real-world cases (clean approvals, clear declines, and ambiguous files with missing information). Because no private data is used, the materials are easy to share and extend.\n",
        "\n",
        "## How to read the results\n",
        "- **Decision table:** Counts of Accept / Decline / Refer.\n",
        "- **Rationale check:** How often the stated reason matches the expected reason type.\n",
        "- **Example cases:** A few end-to-end samples with the cited rule text and the assistant’s short explanation.\n",
        "\n",
        "## Extend the demo (optional)\n",
        "- Swap in your own rules or forms to see how the flow adapts.\n",
        "- Compare alternative approaches (e.g., different retrieval settings or model versions) using the same dataset.\n",
        "- Add checkpoints for **claims triage** or **trend/change detection** using the same agent pattern.\n",
        "\n",
        "---\n",
        "\n",
        "**Authors:** Robert Richardson\n",
        "**Contact:** richardson@stat.byu.edu  \n",
        "**Notebook:** [Agentic_RAG_Underwriting-2.ipynb](Agentic_RAG_Underwriting-2.ipynb)\n"
      ],
      "metadata": {
        "id": "SzGYCV2-rigR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary packages (specifically for use on Google Colab)"
      ],
      "metadata": {
        "id": "7HoCDCrDqT5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain openai faiss-cpu pymupdf langchain-community tiktoken langchain-openai langgraph pypdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQi3zcNpyWIr",
        "outputId": "58f6b8d2-c7c9-4bed-e339-fd755e7cdb35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.5.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.71)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.74-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.5.4-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.7/309.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.74-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, pypdf, pymupdf, ormsgpack, mypy-extensions, marshmallow, httpx-sse, faiss-cpu, typing-inspect, pydantic-settings, langgraph-sdk, dataclasses-json, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.11.0.post1 httpx-sse-0.4.1 langchain-community-0.3.27 langchain-openai-0.3.28 langgraph-0.5.4 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.74 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.10.0 pydantic-settings-2.10.1 pymupdf-1.26.3 pypdf-5.8.0 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bphCHJ7KqeTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load required libraries"
      ],
      "metadata": {
        "id": "RcDncJRUqgv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Non-Linear Agentic RAG Underwriting Pipeline (fully integrated)\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openai\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "import json\n",
        "from typing import Tuple\n",
        "from datetime import datetime\n",
        "import langgraph as lg\n",
        "from langgraph.graph import StateGraph\n"
      ],
      "metadata": {
        "id": "qjDSKhh31aXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently using OPENAI API key"
      ],
      "metadata": {
        "id": "jN5KRlTpqjSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "# Setup environment and API key\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "onsWJyXQ1foX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the policy guideline into a vector store"
      ],
      "metadata": {
        "id": "9sMPP139qmc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Vectorize Policy Guide\n",
        "loader = PyPDFLoader('https://raw.githubusercontent.com/drbob-richardson/Actuarial_Agentic_AI/main/bop_agentic_rag/Application_Data_Generation/bop_policyguide_draft2.pdf')\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Load SIC codes\n",
        "sic_codes_df = pd.read_csv('https://raw.githubusercontent.com/drbob-richardson/Actuarial_Agentic_AI/main/bop_agentic_rag/Application_Data_Generation/sic-codes.csv')\n",
        "acceptable_sics = set(sic_codes_df['SIC'].astype(str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOg4WiIf1iiS",
        "outputId": "30f81078-75c9-461d-d4b7-6d512c9949c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-3596975118.py:8: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make helper functions and create pipeline"
      ],
      "metadata": {
        "id": "8u-TK5PcqyAH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm2Okcz9npUa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def parse_money(value):\n",
        "    try:\n",
        "        if isinstance(value, str):\n",
        "            # Remove all characters except digits, periods, slashes, and commas\n",
        "            cleaned = re.sub(r'[^\\d\\.\\-]', '', value)\n",
        "            return float(cleaned)\n",
        "        return float(value)\n",
        "    except Exception as e:\n",
        "        print(f\"[parse_money error] Could not parse value '{value}': {e}\")\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "\n",
        "# Logistic regression rating function (as defined previously)\n",
        "def calculate_combined_bop_factor(\n",
        "    year_built: int,\n",
        "    sq_ft: float,\n",
        "    building_limit: float,\n",
        "    distance_to_hydrant: float,\n",
        "    prior_loss_count: int,\n",
        "    annual_sales: float,\n",
        "    sic_code: str,\n",
        "    current_year: int = datetime.now().year\n",
        ") -> Tuple[float, float, float]:\n",
        "    sic_code = str(sic_code).zfill(4)\n",
        "    sic_base_rates = {\"20\": 0.40, \"50\": 0.40, \"52\": 0.35, \"53\": 0.35, \"54\": 0.35,\n",
        "                      \"55\": 0.35, \"56\": 0.35, \"57\": 0.35, \"58\": 0.70, \"59\": 0.35,\n",
        "                      \"72\": 0.55, \"73\": 0.55, \"75\": 0.55, \"76\": 0.55, \"80\": 0.50,\n",
        "                      \"81\": 0.50, \"82\": 0.50, \"87\": 0.50, \"40\": 0.45, \"41\": 0.45,\n",
        "                      \"42\": 0.45, \"48\": 0.45}\n",
        "    base_rate = sic_base_rates.get(sic_code[:2], 0.50)\n",
        "    age_factor = .75 + 0.0075 * min(current_year - year_built, 80)\n",
        "    sq_ft_factor = (sq_ft / 2000) ** 0.15\n",
        "    limit_factor = min(1 + 0.002 * max(0, building_limit / 1000 - 250), 3.0)\n",
        "    hydrant_factor = min(1 + 0.00003 * distance_to_hydrant, 1.30)\n",
        "    loss_factor = min(1.0 * (1.25 ** prior_loss_count), 3.0)\n",
        "    sales_factor = (annual_sales / 100_000) ** 0.10\n",
        "    total_factor = (age_factor * sq_ft_factor * limit_factor * hydrant_factor * loss_factor * sales_factor * base_rate)\n",
        "    return round(total_factor, 3), round(max(min(total_factor, 2.5), 0.5), 3), round(base_rate, 3)\n",
        "\n",
        "def retrieve_underwriting_guidelines(business_type, application_data=None):\n",
        "    # Basic\n",
        "    business_docs = retriever.invoke(f\"Underwriting guidelines for {business_type}\")\n",
        "    global_docs = retriever.invoke(\"General underwriting guidelines and exclusions\")\n",
        "\n",
        "    # LLM-enhanced retrieval\n",
        "    if application_data:\n",
        "        query = generate_guideline_retrieval_query(application_data)\n",
        "        smart_docs = retriever.invoke(query)\n",
        "    else:\n",
        "        smart_docs = []\n",
        "\n",
        "    # Merge and deduplicate\n",
        "    seen = set()\n",
        "    all_docs = []\n",
        "    for doc in business_docs + global_docs + smart_docs:\n",
        "        if doc.page_content not in seen:\n",
        "            seen.add(doc.page_content)\n",
        "            all_docs.append(doc)\n",
        "\n",
        "    return \"\\n\\n---\\n\\n\".join(doc.page_content for doc in all_docs)\n",
        "\n",
        "\n",
        "\n",
        "# LLM setup\n",
        "llm = ChatOpenAI(model_name='gpt-4.1-mini', temperature=0)\n",
        "qa = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
        "\n",
        "def check_sic_node(state):\n",
        "    application = state['application']\n",
        "    sic = application.get('SIC')\n",
        "    prompt = f\"\"\"\n",
        "    Is SIC code {sic} clearly appropriate for a business described as '{application['NATURE OF BUSINESS']}'?\n",
        "    Respond with one of the following formats exactly:\n",
        "\n",
        "    - YES - followed by reasoning\n",
        "    - NO - followed by reasoning\n",
        "\n",
        "    Example: YES - The SIC code aligns well with the described antique retail business.\n",
        "\n",
        "    Your answer:\n",
        "    \"\"\"\n",
        "    evaluation = llm.invoke(prompt).content.strip().upper()\n",
        "\n",
        "    if 'NO' in evaluation:\n",
        "        state.update({'decision': 'REJECT', 'reason': evaluation})\n",
        "    elif 'YES' in evaluation:\n",
        "        state.update({'decision': 'CONTINUE', 'reason': evaluation})\n",
        "    else:\n",
        "        state.update({'decision': 'REQUIRES_HUMAN_REVIEW', 'reason': f'Ambiguous SIC evaluation: {evaluation}'})\n",
        "    return state\n",
        "\n",
        "\n",
        "def guidelines_eval_node(state):\n",
        "    application = state['application']\n",
        "    guidelines = retrieve_underwriting_guidelines(application['NATURE OF BUSINESS'])\n",
        "\n",
        "    prompt = (\n",
        "        f\"Given this application: {json.dumps(application)}\\n\\n\"\n",
        "        f\"Guidelines:\\n{guidelines}\\n\\n\"\n",
        "        \"Categorize the application's underwriting acceptability as:\\n\"\n",
        "        \"- CLEARLY_ACCEPTABLE\\n\"\n",
        "        \"- CLEARLY_REJECTABLE\\n\"\n",
        "        \"- BORDERLINE_REQUIRES_THIRD_PARTY\\n\"\n",
        "        \"- APPETITE_UNCLEAR\\n\\n\"\n",
        "        \"Respond with a category and a short explanation. Example:\\n\"\n",
        "        \"CLEARLY_ACCEPTABLE - The business aligns fully with listed criteria.\"\n",
        "    )\n",
        "\n",
        "    evaluation = llm.invoke(prompt).content.upper()\n",
        "\n",
        "    if 'CLEARLY_ACCEPTABLE' in evaluation:\n",
        "        decision = 'CLEARLY_ACCEPTABLE'\n",
        "    elif 'CLEARLY_REJECTABLE' in evaluation:\n",
        "        decision = 'CLEARLY_REJECTABLE'\n",
        "    elif 'BORDERLINE_REQUIRES_THIRD_PARTY' in evaluation:\n",
        "        decision = 'BORDERLINE_REQUIRES_THIRD_PARTY'\n",
        "    elif 'APPETITE_UNCLEAR' in evaluation:\n",
        "        decision = 'APPETITE_UNCLEAR'\n",
        "    elif 'ACCEPTABLE' in evaluation and 'UNCLEAR' not in evaluation:\n",
        "        decision = 'CLEARLY_ACCEPTABLE'  # fallback from soft language\n",
        "    else:\n",
        "        decision = 'APPETITE_UNCLEAR'  # default to unclear, but allow reflection\n",
        "\n",
        "    state.update({\n",
        "        'decision': decision,\n",
        "        'guidelines': guidelines,\n",
        "        'reason': evaluation\n",
        "    })\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "def logistic_eval_node(state):\n",
        "    application = state['application']\n",
        "    third_party_data = state.get('third_party_data', {})\n",
        "\n",
        "    try:\n",
        "        total_factor, total_factor_capped, base_rate = calculate_combined_bop_factor(\n",
        "            year_built=int(application['Year Built']),\n",
        "            sq_ft=float(application['Square Feet']),\n",
        "            building_limit=parse_money(application['Building limit']),\n",
        "            annual_sales=parse_money(application['ANNUAL SALES']),\n",
        "            distance_to_hydrant=float(application['Distance to hydrant'].split()[0]),\n",
        "            prior_loss_count=int(third_party_data.get('Number of Claims', 0)),\n",
        "            sic_code=application['SIC']\n",
        "        )\n",
        "\n",
        "\n",
        "        decision = 'ACCEPT' if total_factor_capped < 1.5 else 'REFER' if total_factor_capped < 2.0 else 'REJECT'\n",
        "\n",
        "    except Exception as e:\n",
        "        total_factor_capped = float('nan')\n",
        "        logistic_reason = f\"Logistic score could not be calculated: {e}\"\n",
        "        decision = 'REJECT'\n",
        "    logistic_reason = f'Logistic factor capped: {total_factor_capped}'\n",
        "    state.update({\n",
        "        'final_decision': decision,\n",
        "        'logistic_reason': logistic_reason,\n",
        "        'reason': logistic_reason\n",
        "    })\n",
        "    return state\n",
        "\n",
        "\n",
        "def reflection_node(state):\n",
        "    state['reflection_count'] = state.get('reflection_count', 0) + 1\n",
        "\n",
        "    if state['reflection_count'] > 2:\n",
        "        # Allow fallback to logistic scoring instead of forcing human review\n",
        "        state['decision'] = 'CLEAR_FOR_LOGISTIC'\n",
        "        state['reason'] = 'Guideline uncertainty unresolved after 3 reflections — proceeding to logistic evaluation.'\n",
        "        return state\n",
        "\n",
        "    application = state['application']\n",
        "    uncertainties = state.get('decision', 'appetite level unclear')\n",
        "    guidelines = retrieve_underwriting_guidelines(application['NATURE OF BUSINESS'])\n",
        "\n",
        "    prompt = (\n",
        "        f\"Clarify the underwriting appetite decision based on the current uncertainty: '{uncertainties}'.\\n\\n\"\n",
        "        f\"Application:\\n{json.dumps(application)}\\n\\n\"\n",
        "        f\"Guidelines:\\n{guidelines}\\n\\n\"\n",
        "        \"Respond with one of the following categories ONLY, followed by a short justification:\\n\"\n",
        "        \"- CLEARLY_ACCEPTABLE\\n- CLEARLY_REJECTABLE\\n- BORDERLINE_REQUIRES_THIRD_PARTY\\n- APPETITE_UNCLEAR\\n\"\n",
        "    )\n",
        "    reflection_result = llm.invoke(prompt).content\n",
        "    state.update({'reflection': reflection_result})\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Restore expanded third-party data evaluation node\n",
        "def third_party_eval_node(state):\n",
        "    application = state['application']\n",
        "    guidelines = retrieve_underwriting_guidelines(application['NATURE OF BUSINESS'])\n",
        "\n",
        "    prompt = (\n",
        "        f\"Third-party data:\\n{json.dumps(state['third_party_data'])}\\n\\n\"\n",
        "        f\"Guidelines:\\n{guidelines}\\n\\n\"\n",
        "        \"Categorize this data as one of:\\n\"\n",
        "        \"- DISQUALIFYING_FACTORS_PRESENT\\n\"\n",
        "        \"- UNCLEAR_REQUIRES_REVIEW\\n\"\n",
        "        \"- CLEAR\\n\\n\"\n",
        "        \"Respond with the category and a brief explanation.\"\n",
        "    )\n",
        "    evaluation = llm.invoke(prompt).content.upper()\n",
        "\n",
        "    if 'DISQUALIFYING_FACTORS_PRESENT' in evaluation:\n",
        "        state.update({'final_decision': 'REJECT', 'reason': evaluation})\n",
        "    elif 'UNCLEAR_REQUIRES_REVIEW' in evaluation:\n",
        "        state.update({'decision': 'CLEAR_FOR_LOGISTIC', 'third_party_evaluation': evaluation})\n",
        "    elif 'CLEAR' in evaluation:\n",
        "        state.update({'third_party_evaluation': evaluation, 'decision': 'CLEAR_FOR_LOGISTIC'})\n",
        "    else:\n",
        "        # Assume fallback to logistic\n",
        "        state.update({'decision': 'CLEAR_FOR_LOGISTIC', 'third_party_evaluation': f'Ambiguous: {evaluation}'})\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def concerning_details_check_node(state):\n",
        "    application = state['application']\n",
        "    guidelines = retrieve_underwriting_guidelines(application['NATURE OF BUSINESS'])\n",
        "\n",
        "    prompt = (\n",
        "        f\"Review this application: {json.dumps(application)}\\n\\n\"\n",
        "        f\"Using the following underwriting guidelines:\\n\\n{guidelines}\\n\\n\"\n",
        "        \"List any potentially concerning details in the application that are NOT directly addressed or clearly covered by the guidelines.\\n\"\n",
        "        \"Only include items that may require clarification or pose potential issues beyond what's defined in the guidelines.\\n\\n\"\n",
        "        \"Respond with either:\\n\"\n",
        "        \"- NO CONCERNS if everything aligns or is irrelevant to the guidelines\\n\"\n",
        "        \"- A numbered list of unclear or missing information\\n\\n\"\n",
        "        \"Do not suggest rejection or human review — only identify the guideline coverage status of the concerns.\"\n",
        "    )\n",
        "\n",
        "    concerns = llm.invoke(prompt).content.strip()\n",
        "\n",
        "    if \"NO CONCERNS\" in concerns.upper():\n",
        "        state.update({'concerning_details': None})\n",
        "        return state\n",
        "    else:\n",
        "        state.update({\n",
        "            'concerning_details': concerns,\n",
        "            'decision': 'REFLECT_CONCERNS',\n",
        "            'reason': concerns\n",
        "        })\n",
        "        return state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "def reflect_concerns_node(state):\n",
        "    application = state['application']\n",
        "    concerns = state.get('concerning_details')\n",
        "    business_type = application.get('NATURE OF BUSINESS', 'Retail')\n",
        "\n",
        "    # LLM-based retrieval query for reflection\n",
        "    smart_query = generate_guideline_retrieval_query(application)\n",
        "    smart_docs = retriever.invoke(smart_query)\n",
        "    business_docs = retriever.invoke(f\"Underwriting guidelines for {business_type}\")\n",
        "    global_docs = retriever.invoke(\"General underwriting guidelines and exclusions\")\n",
        "\n",
        "    # Combine and deduplicate guidelines\n",
        "    seen = set()\n",
        "    all_docs = []\n",
        "    for doc in smart_docs + business_docs + global_docs:\n",
        "        if doc.page_content not in seen:\n",
        "            seen.add(doc.page_content)\n",
        "            all_docs.append(doc)\n",
        "\n",
        "    guidelines = \"\\n\\n---\\n\\n\".join(doc.page_content for doc in all_docs)\n",
        "\n",
        "    prompt = (\n",
        "        f\"The following concerns were identified in the application:\\n{concerns}\\n\\n\"\n",
        "        f\"Underwriting Guidelines:\\n{guidelines}\\n\\n\"\n",
        "        \"Question:\\nDo ANY of these concerns explicitly violate the underwriting guidelines?\\n\\n\"\n",
        "        \"Respond with one of the following formats only:\\n\"\n",
        "        \"- YES – followed by a short summary of the violating concern(s)\\n\"\n",
        "        \"- NO – followed by a statement confirming no explicit violations\\n\\n\"\n",
        "        \"Be concise. Do not re-list the concerns or over-explain.\"\n",
        "    )\n",
        "\n",
        "    reflection_output = llm.invoke(prompt).content.strip()\n",
        "    state['reflection_outcome'] = reflection_output\n",
        "    state['retrieval_query'] = smart_query  # Optional audit field\n",
        "\n",
        "    reflection_upper = reflection_output.upper()\n",
        "\n",
        "    if reflection_upper.startswith(\"YES\"):\n",
        "        state['final_decision'] = 'REJECT'\n",
        "        state['reason'] = f\"Rejected due to guideline violation: {reflection_output}\"\n",
        "    elif reflection_upper.startswith(\"NO\"):\n",
        "        state['decision'] = 'CLEAR_FOR_LOGISTIC'\n",
        "        state['reason'] = \"No explicit guideline violations found.\"\n",
        "    else:\n",
        "        state['final_decision'] = 'REQUIRES_HUMAN_REVIEW'\n",
        "        state['reason'] = f\"Uninterpretable reflection result:\\n{reflection_output}\"\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_guideline_retrieval_query(application_data):\n",
        "    prompt = f\"\"\"\n",
        "    Given the following business insurance application, generate a precise and specific query to retrieve underwriting guidelines that may apply to edge-case concerns or risks.\n",
        "\n",
        "    Application Data:\n",
        "    {json.dumps(application_data, indent=2)}\n",
        "\n",
        "    Focus especially on:\n",
        "    - Risky or unusual fields\n",
        "    - Claimed losses, prior incidents, or unusual coverages\n",
        "    - Fields that might match underwriting exclusions\n",
        "\n",
        "    Respond with a single-line retrieval query targeting specific underwriting rules or exclusions:\n",
        "    \"\"\"\n",
        "    query = llm.invoke(prompt).content.strip()\n",
        "    return query\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def final_reject_node(state):\n",
        "    state['final_decision'] = 'REJECT'\n",
        "\n",
        "    # Use logistic reason if present\n",
        "    if \"logistic_reason\" in state and state[\"logistic_reason\"]:\n",
        "        state['reason'] = state['logistic_reason']\n",
        "    elif \"reason\" in state and state[\"reason\"]:\n",
        "        state['reason'] = state['reason']\n",
        "    else:\n",
        "        state['reason'] = \"Rejected without specified reason\"\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def human_review_node(state):\n",
        "    state['final_decision'] = 'REQUIRES_HUMAN_REVIEW'\n",
        "    state['reason'] = state.get('reason', 'Ambiguity or risk details require human intervention.')\n",
        "    return state\n",
        "\n",
        "\n",
        "from typing import TypedDict, Optional\n",
        "\n",
        "class UnderwritingState(TypedDict):\n",
        "    application: dict\n",
        "    third_party_data: Optional[dict]\n",
        "    decision: Optional[str]\n",
        "    final_decision: Optional[str]\n",
        "    reason: Optional[str]\n",
        "    guidelines: Optional[str]\n",
        "    reflection: Optional[str]\n",
        "    reflection_count: Optional[int]\n",
        "    logistic_reason: Optional[str]\n",
        "    concerning_details: Optional[str]\n",
        "    reflection_outcome: Optional[str]\n",
        "    third_party_evaluation: Optional[str]\n",
        "\n",
        "\n",
        "flow = StateGraph(UnderwritingState)\n",
        "\n",
        "# Nodes (already defined by you)\n",
        "flow.add_node('SIC_CHECK', check_sic_node)\n",
        "flow.add_node('GUIDELINES_EVAL', guidelines_eval_node)\n",
        "flow.add_node('THIRD_PARTY_EVAL', third_party_eval_node)\n",
        "flow.add_node('REFLECTION_NODE', reflection_node)\n",
        "flow.add_node('LOGISTIC_EVAL', logistic_eval_node)\n",
        "flow.add_node('CONCERNING_DETAILS_CHECK', concerning_details_check_node)\n",
        "flow.add_node('REFLECT_CONCERNS', reflect_concerns_node)\n",
        "flow.add_node('HUMAN_REVIEW', human_review_node)\n",
        "flow.add_node('FINAL_REJECT', final_reject_node)\n",
        "\n",
        "# Entry Point\n",
        "flow.set_entry_point('SIC_CHECK')\n",
        "\n",
        "# SIC_CHECK always goes to GUIDELINES_EVAL unless immediately rejected\n",
        "flow.add_edge('SIC_CHECK', 'GUIDELINES_EVAL')\n",
        "\n",
        "# GUIDELINES_EVAL Conditional Router\n",
        "def guidelines_router(state):\n",
        "    decision = state['decision']\n",
        "    reflections = state.get('reflection_count', 0)\n",
        "\n",
        "    if decision == 'CLEARLY_REJECTABLE':\n",
        "        return 'FINAL_REJECT'\n",
        "    elif decision == 'BORDERLINE_REQUIRES_THIRD_PARTY':\n",
        "        return 'THIRD_PARTY_EVAL'\n",
        "    elif decision == 'APPETITE_UNCLEAR':\n",
        "        if reflections >= 2:\n",
        "            return 'LOGISTIC_EVAL'  # fallback path\n",
        "        return 'REFLECTION_NODE'\n",
        "    elif decision == 'CLEARLY_ACCEPTABLE':\n",
        "        return 'CONCERNING_DETAILS_CHECK'\n",
        "    else:\n",
        "        return 'HUMAN_REVIEW'\n",
        "\n",
        "\n",
        "\n",
        "flow.add_conditional_edges('GUIDELINES_EVAL', guidelines_router)\n",
        "\n",
        "# THIRD_PARTY_EVAL Conditional Router\n",
        "def third_party_router(state):\n",
        "    if state.get('final_decision') == 'REJECT':\n",
        "        return 'FINAL_REJECT'\n",
        "    elif state.get('final_decision') == 'REQUIRES_HUMAN_REVIEW':\n",
        "        return 'HUMAN_REVIEW'\n",
        "    elif state.get('decision') == 'CLEAR_FOR_LOGISTIC':\n",
        "        return 'LOGISTIC_EVAL'\n",
        "    else:\n",
        "        return 'HUMAN_REVIEW'\n",
        "\n",
        "\n",
        "flow.add_conditional_edges('THIRD_PARTY_EVAL', third_party_router)\n",
        "\n",
        "# REFLECTION_NODE loops back to GUIDELINES_EVAL\n",
        "flow.add_edge('REFLECTION_NODE', 'GUIDELINES_EVAL')\n",
        "\n",
        "# CONCERNING_DETAILS_CHECK Conditional Router\n",
        "def reflect_concerns_router(state):\n",
        "    outcome = state.get('reflection_outcome', '').lower()\n",
        "    return 'LOGISTIC_EVAL'\n",
        "\n",
        "def concerns_router(state):\n",
        "    if state.get('decision') == 'REFLECT_CONCERNS':\n",
        "        return 'REFLECT_CONCERNS'\n",
        "    else:\n",
        "        return 'LOGISTIC_EVAL'\n",
        "\n",
        "\n",
        "flow.add_conditional_edges('CONCERNING_DETAILS_CHECK', concerns_router)\n",
        "\n",
        "# REFLECT_CONCERNS Conditional Router\n",
        "def reflect_concerns_router(state):\n",
        "    if state.get('decision') == 'CLEAR_FOR_LOGISTIC':\n",
        "        return 'LOGISTIC_EVAL'\n",
        "    elif state.get('final_decision') == 'REJECT':\n",
        "        return 'FINAL_REJECT'\n",
        "    else:\n",
        "        return 'HUMAN_REVIEW'\n",
        "\n",
        "\n",
        "\n",
        "flow.add_conditional_edges('REFLECT_CONCERNS', reflect_concerns_router)\n",
        "\n",
        "# LOGISTIC_EVAL Conditional Router (final decision)\n",
        "def logistic_router(state):\n",
        "    decision = state.get('final_decision', '').upper()\n",
        "    if decision == 'ACCEPT':\n",
        "        return 'ACCEPT'  # Define or handle acceptance clearly\n",
        "    elif decision == 'REJECT':\n",
        "        return 'FINAL_REJECT'\n",
        "    else:  # REFER or ambiguous outcomes\n",
        "        return 'HUMAN_REVIEW'\n",
        "\n",
        "# Add explicit ACCEPT node for clarity\n",
        "def accept_node(state):\n",
        "    state['reason'] = state.get('logistic_reason', 'Accepted per logistic evaluation.')\n",
        "    return state\n",
        "\n",
        "flow.add_node('ACCEPT', accept_node)\n",
        "\n",
        "flow.add_conditional_edges('LOGISTIC_EVAL', logistic_router)\n",
        "\n",
        "\n",
        "\n",
        "app = flow.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access data"
      ],
      "metadata": {
        "id": "kHFeoUo2q3Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import openai\n",
        "\n",
        "\n",
        "# 1. List all files in the public GitHub folder using raw.githubusercontent.com\n",
        "base_url = \"https://raw.githubusercontent.com/drbob-richardson/Actuarial_Agentic_AI/main/bop_agentic_rag/Application_Data_Generation/Application_Data/ToAccept/\"\n",
        "\n",
        "import requests\n",
        "\n",
        "# Load the filelist.txt from the GitHub repo\n",
        "filelist_url = \"https://raw.githubusercontent.com/drbob-richardson/Actuarial_Agentic_AI/main/bop_agentic_rag/Application_Data_Generation/Application_Data/ToAccept/filelist.txt\"\n",
        "\n",
        "response = requests.get(filelist_url)\n",
        "response.raise_for_status()\n",
        "\n",
        "# Get the list of filenames\n",
        "filenames = [line.strip() for line in response.text.splitlines() if line.strip()]\n",
        "print(f\"Loaded {len(filenames)} filenames from GitHub.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48sgal2G7OMk",
        "outputId": "684c0714-041c-4712-c20d-98f2e74e022c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 127 filenames from GitHub.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the data through the pipeline\n"
      ],
      "metadata": {
        "id": "_md5fbh_q5uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = filenames[51:60]\n",
        "\n",
        "def get_embedding(text: str, model: str = \"text-embedding-ada-002\") -> list:\n",
        "    response = openai.embeddings.create(input=[text], model=model)\n",
        "    return response.data[0].embedding\n",
        "\n",
        "def cosine_similarity(vec1: list, vec2: list) -> float:\n",
        "    a = np.array(vec1)\n",
        "    b = np.array(vec2)\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "\n",
        "results = []\n",
        "for fname in tqdm(filenames):\n",
        "    url = base_url + requests.utils.quote(fname, safe=\"()\")\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        app_data = data.get(\"Application Data\", {})\n",
        "        third_party = data.get(\"Third-Party Data\", {})\n",
        "        expected_decision = data.get(\"Final Decision\", \"\").strip().upper()\n",
        "        expected_reason = data.get(\"Final Reason\", \"\")\n",
        "\n",
        "        result = app.invoke({\"application\": app_data, \"third_party_data\": third_party})\n",
        "\n",
        "        predicted = result.get(\"final_decision\", \"MISSING\").strip().upper()\n",
        "        reason = result.get(\"reason\", \"\")\n",
        "        print(\"Expected decision values:\")\n",
        "        print(expected_decision)\n",
        "\n",
        "        print(\"\\nPredicted decision values:\")\n",
        "        print(predicted)\n",
        "\n",
        "        results.append({\n",
        "            \"file\": fname,\n",
        "            \"expected_decision\": expected_decision,\n",
        "            \"predicted_decision\": predicted,\n",
        "            \"expected_reason\": expected_reason,\n",
        "            \"predicted_reason\": reason,\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        results.append({\n",
        "            \"file\": fname,\n",
        "            \"expected_decision\": \"ERROR\",\n",
        "            \"predicted_decision\": \"ERROR\",\n",
        "            \"expected_reason\": \"\",\n",
        "            \"predicted_reason\": str(e),\n",
        "        })\n",
        "\n",
        "# 2. Evaluation\n",
        "df = pd.DataFrame(results)\n",
        "valid = df[~df[\"expected_decision\"].isin([\"ERROR\", \"\"]) & ~df[\"predicted_decision\"].isin([\"ERROR\", \"MISSING\"])]\n",
        "\n",
        "# Accuracy and classification metrics\n",
        "y_true = valid[\"expected_decision\"]\n",
        "y_pred = valid[\"predicted_decision\"]\n",
        "print(\"\\n=== Decision Evaluation ===\")\n",
        "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.3f}\")\n",
        "print(confusion_matrix(y_true, y_pred, labels=[\"ACCEPT\", \"REFER\", \"REJECT\", \"REQUIRES_HUMAN_REVIEW\"]))\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# 3. Semantic similarity of reasons (optional, uses OpenAI embeddings)\n",
        "def safe_similarity(a, b):\n",
        "    try:\n",
        "        emb1 = get_embedding(a, engine=\"text-embedding-ada-002\")\n",
        "        emb2 = get_embedding(b, engine=\"text-embedding-ada-002\")\n",
        "        return cosine_similarity(emb1, emb2)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "print(\"\\n=== Reason Similarity Evaluation ===\")\n",
        "valid[\"reason_similarity\"] = valid.apply(lambda row: safe_similarity(row[\"expected_reason\"], row[\"predicted_reason\"]), axis=1)\n",
        "print(f\"Average semantic similarity of reasons: {valid['reason_similarity'].dropna().mean():.3f}\")\n",
        "\n",
        "# Save results to CSV\n",
        "valid.to_csv(\"decision_eval_results.csv\", index=False)\n",
        "print(\"\\nEvaluation results saved to 'decision_eval_results.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiBkcpa47BkV",
        "outputId": "189b6b80-6d12-4e66-f454-32dc9690f4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 1/9 [00:16<02:12, 16.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected decision values:\n",
            "ACCEPT\n",
            "\n",
            "Predicted decision values:\n",
            "ACCEPT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 2/9 [00:39<02:21, 20.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected decision values:\n",
            "ACCEPT\n",
            "\n",
            "Predicted decision values:\n",
            "REQUIRES_HUMAN_REVIEW\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 3/9 [00:52<01:42, 17.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected decision values:\n",
            "ACCEPT\n",
            "\n",
            "Predicted decision values:\n",
            "REJECT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 4/9 [01:04<01:14, 14.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected decision values:\n",
            "ACCEPT\n",
            "\n",
            "Predicted decision values:\n",
            "REQUIRES_HUMAN_REVIEW\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 5/9 [01:17<00:57, 14.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected decision values:\n",
            "ACCEPT\n",
            "\n",
            "Predicted decision values:\n",
            "ACCEPT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 6/9 [01:29<00:40, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected decision values:\n",
            "ACCEPT\n",
            "\n",
            "Predicted decision values:\n",
            "ACCEPT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 7/9 [01:39<00:24, 12.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected decision values:\n",
            "ACCEPT\n",
            "\n",
            "Predicted decision values:\n",
            "ACCEPT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 8/9 [01:49<00:11, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected decision values:\n",
            "ACCEPT\n",
            "\n",
            "Predicted decision values:\n",
            "ACCEPT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [02:03<00:00, 13.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected decision values:\n",
            "ACCEPT\n",
            "\n",
            "Predicted decision values:\n",
            "ACCEPT\n",
            "\n",
            "=== Decision Evaluation ===\n",
            "Accuracy: 0.667\n",
            "[[6 0 1 2]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]]\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "               ACCEPT       1.00      0.67      0.80         9\n",
            "               REJECT       0.00      0.00      0.00         0\n",
            "REQUIRES_HUMAN_REVIEW       0.00      0.00      0.00         0\n",
            "\n",
            "             accuracy                           0.67         9\n",
            "            macro avg       0.33      0.22      0.27         9\n",
            "         weighted avg       1.00      0.67      0.80         9\n",
            "\n",
            "\n",
            "=== Reason Similarity Evaluation ===\n",
            "Average semantic similarity of reasons: nan\n",
            "\n",
            "Evaluation results saved to 'decision_eval_results.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "E2tExA7sGpso",
        "outputId": "bcce84d2-6020-464f-aa06-5073cc46662d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             file expected_decision  \\\n",
              "0      Delicatessens _ Sandwich Shops_84718d.json            ACCEPT   \n",
              "1        Department _ Discount Stores_ef2690.json            ACCEPT   \n",
              "2                       Dessert Shops_030e06.json            ACCEPT   \n",
              "3       Detective _ Security Services_840160.json            ACCEPT   \n",
              "4             Diaper _ Linen Services_610616.json            ACCEPT   \n",
              "5    Door _ Window Installation_Sales_09bad5.json            ACCEPT   \n",
              "6     Dry Cleaning _ Laundry Services_d6d47b.json            ACCEPT   \n",
              "7  Educational _ School Supply Stores_ebbb0b.json            ACCEPT   \n",
              "8     Electrical Equipment _ Supplies_3f501f.json            ACCEPT   \n",
              "\n",
              "      predicted_decision                                    expected_reason  \\\n",
              "0                 ACCEPT  The application aligns with underwriting guide...   \n",
              "1  REQUIRES_HUMAN_REVIEW  The application aligns with underwriting guide...   \n",
              "2                 REJECT  The application meets all underwriting guideli...   \n",
              "3  REQUIRES_HUMAN_REVIEW  The application aligns with the underwriting g...   \n",
              "4                 ACCEPT  The application meets all underwriting guideli...   \n",
              "5                 ACCEPT  The application aligns with the underwriting g...   \n",
              "6                 ACCEPT  The application aligns with underwriting guide...   \n",
              "7                 ACCEPT  The application meets all underwriting guideli...   \n",
              "8                 ACCEPT  The application meets all underwriting guideli...   \n",
              "\n",
              "                                    predicted_reason  \n",
              "0                      Logistic factor capped: 1.384  \n",
              "1                      Logistic factor capped: 1.876  \n",
              "2  Rejected due to guideline violation: YES – The...  \n",
              "3                       Logistic factor capped: 1.57  \n",
              "4                      Logistic factor capped: 1.347  \n",
              "5                      Logistic factor capped: 1.376  \n",
              "6                       Logistic factor capped: 1.18  \n",
              "7                      Logistic factor capped: 0.983  \n",
              "8                      Logistic factor capped: 1.073  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-607bcb09-7051-4a40-bf4c-f351ff390814\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>expected_decision</th>\n",
              "      <th>predicted_decision</th>\n",
              "      <th>expected_reason</th>\n",
              "      <th>predicted_reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Delicatessens _ Sandwich Shops_84718d.json</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>The application aligns with underwriting guide...</td>\n",
              "      <td>Logistic factor capped: 1.384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Department _ Discount Stores_ef2690.json</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>REQUIRES_HUMAN_REVIEW</td>\n",
              "      <td>The application aligns with underwriting guide...</td>\n",
              "      <td>Logistic factor capped: 1.876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dessert Shops_030e06.json</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>REJECT</td>\n",
              "      <td>The application meets all underwriting guideli...</td>\n",
              "      <td>Rejected due to guideline violation: YES – The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Detective _ Security Services_840160.json</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>REQUIRES_HUMAN_REVIEW</td>\n",
              "      <td>The application aligns with the underwriting g...</td>\n",
              "      <td>Logistic factor capped: 1.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Diaper _ Linen Services_610616.json</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>The application meets all underwriting guideli...</td>\n",
              "      <td>Logistic factor capped: 1.347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Door _ Window Installation_Sales_09bad5.json</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>The application aligns with the underwriting g...</td>\n",
              "      <td>Logistic factor capped: 1.376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Dry Cleaning _ Laundry Services_d6d47b.json</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>The application aligns with underwriting guide...</td>\n",
              "      <td>Logistic factor capped: 1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Educational _ School Supply Stores_ebbb0b.json</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>The application meets all underwriting guideli...</td>\n",
              "      <td>Logistic factor capped: 0.983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Electrical Equipment _ Supplies_3f501f.json</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>ACCEPT</td>\n",
              "      <td>The application meets all underwriting guideli...</td>\n",
              "      <td>Logistic factor capped: 1.073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-607bcb09-7051-4a40-bf4c-f351ff390814')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-607bcb09-7051-4a40-bf4c-f351ff390814 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-607bcb09-7051-4a40-bf4c-f351ff390814');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-492adc22-adfe-46ac-9512-be41f7da5a4c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-492adc22-adfe-46ac-9512-be41f7da5a4c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-492adc22-adfe-46ac-9512-be41f7da5a4c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9fae1a51-067c-4603-8936-dad192647f62\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9fae1a51-067c-4603-8936-dad192647f62 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"file\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Educational _ School Supply Stores_ebbb0b.json\",\n          \"Department _ Discount Stores_ef2690.json\",\n          \"Door _ Window Installation_Sales_09bad5.json\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expected_decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ACCEPT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ACCEPT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expected_reason\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"The application meets all underwriting guidelines, including acceptable inventory levels, no high-risk activities, and a solid financial profile.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_reason\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Logistic factor capped: 0.983\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:,3:5].values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV4Z76_F3TMo",
        "outputId": "bb66c71b-b434-40f5-d2a9-3f8206f4d012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[\"The application is rejected due to a prior theft claim of $2,500, which raises concerns about the business's risk profile and security measures, violating underwriting exclusions for this business type.\",\n",
              "        'Logistic factor capped: 0.705'],\n",
              "       ['The applicant has uncorrected fire code violations, which violates the underwriting guidelines for this business type.',\n",
              "        'Logistic factor capped: nan'],\n",
              "       ['The business has uncorrected fire code violations, which raises significant liability concerns, violating underwriting guidelines.',\n",
              "        'Logistic factor capped: 2.5'],\n",
              "       ['The application is rejected due to uncorrected fire code violations, which pose a significant safety risk to the children in care, violating underwriting guidelines.',\n",
              "        'CLEARLY_REJECTABLE - THE APPLICATION INDICATES UNCORRECTED FIRE CODE VIOLATIONS, WHICH POSE A SIGNIFICANT SAFETY RISK IN A CHILD CARE SETTING AND ARE EXPLICITLY NOTED AS A MAJOR REASON FOR REJECTION. ADDITIONALLY, THE PRESENCE OF RECENT SIGNIFICANT LOSSES, INCLUDING AN OPEN FIRE-RELATED CLAIM, FURTHER INCREASES RISK. ALTHOUGH THE FACILITY OPERATES WITHIN ACCEPTABLE SIZE AND HOURS, THE SAFETY COMPLIANCE ISSUES AND RECENT CLAIMS HISTORY OUTWEIGH PREFERRED OR ACCEPTABLE CRITERIA.'],\n",
              "       ['The application is rejected due to the presence of uncorrected fire code violations, which violates underwriting guidelines for this business type.',\n",
              "        'Logistic factor capped: 0.937'],\n",
              "       ['The business has a history of claims totaling $8,206, which exceeds the acceptable limits for this business type, violating underwriting guidelines.',\n",
              "        'Logistic factor capped: nan'],\n",
              "       ['The business operates in a high-risk industry (SIC 5812 - Dessert Shops) and has been flagged for specific underwriting exclusions that are not met, despite having good credit and reviews.',\n",
              "        'Logistic factor capped: 1.007'],\n",
              "       ['The application is rejected due to a violation of a specific underwriting exclusion related to the nature of operations and potential risks associated with security services.',\n",
              "        'Logistic factor capped: nan'],\n",
              "       ['The application is rejected due to uncorrected fire code violations related to fire hazards in equipment operations, which violates underwriting guidelines for safety compliance.',\n",
              "        'CLEARLY_REJECTABLE - THE APPLICATION SHOWS MULTIPLE SIGNIFICANT RISK FACTORS OUTSIDE ACCEPTABLE UNDERWRITING APPETITE: UNCORRECTED FIRE CODE VIOLATIONS, PAST HAZARDOUS MATERIALS DISPOSAL VIOLATING ENVIRONMENTAL REGULATIONS, RECENT SUBSTANTIAL LOSSES INCLUDING A FIRE AND EMPLOYEE INJURY, AND EXPOSURE TO CHEMICALS. ADDITIONALLY, THE EXPIRATION DATE PRECEDES THE EFFECTIVE DATE, INDICATING DATA INCONSISTENCY. THESE ISSUES PRESENT HIGH SAFETY, ENVIRONMENTAL, AND OPERATIONAL RISKS THAT OUTWEIGH ANY MITIGATING FACTORS.']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    }
  ]
}